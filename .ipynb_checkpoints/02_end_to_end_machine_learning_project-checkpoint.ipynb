{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 â€“ End-to-end Machine Learning project**\n",
    "\n",
    "*Welcome to Machine Learning Housing Corp.! Your task is to predict median house values in Californian districts, given a number of features from these districts Using Java.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%maven commons-io:commons-io:jar:2.6\n",
    "%maven io.vavr:vavr:jar:0.10.0\n",
    "%maven org.apache.commons:commons-compress:1.18\n",
    "%maven tech.tablesaw:tablesaw-core:jar:0.32.7\n",
    "%maven tech.tablesaw:tablesaw-jsplot:jar:0.32.7   \n",
    "%maven nz.ac.waikato.cms.weka:weka-stable:jar:3.8.3\n",
    "%maven nz.ac.waikato.cms.weka:wekaDeeplearning4j:jar:1.5.13\n",
    "    \n",
    "    \n",
    "import org.apache.commons.io.*;\n",
    "import java.io.*;\n",
    "import io.vavr.control.*;\n",
    "import org.apache.commons.compress.archivers.tar.*;\n",
    "import org.apache.commons.compress.compressors.gzip.*;\n",
    "\n",
    "var DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\";\n",
    "var HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\";\n",
    "var PROJECT_ROOT_DIR = \".\";\n",
    "var CHAPTER_ID = \"end_to_end_project\";\n",
    "var HOUSING_PATH = FilenameUtils.concat(\"datasets\", \"housing\");\n",
    "var BUFFER_SIZE = 1024;\n",
    "void fetch_housing_data(String housingUrl, File housingPath){\n",
    "   housingUrl = Objects.toString(housingUrl,HOUSING_URL);\n",
    "   Objects.requireNonNull(housingPath);\n",
    "   if(!housingPath.exists()){\n",
    "       Try.run(() -> FileUtils.forceMkdir(housingPath));\n",
    "   }\n",
    "   var tgzPath = new File(FilenameUtils.concat(housingPath.getPath(), \"housing.tgz\"));\n",
    "   var urlTemp = housingUrl;\n",
    "   Try.run(() -> FileUtils.copyURLToFile(new URL(urlTemp), tgzPath )); \n",
    "   Try.run(() -> extractTarGZ(tgzPath, housingPath) );\n",
    "}\n",
    "\n",
    "void extractTarGZ(File in, File destDir) throws Exception {\n",
    "    GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(new FileInputStream(in));\n",
    "    try (TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {\n",
    "        TarArchiveEntry entry;\n",
    "\n",
    "        while ((entry = (TarArchiveEntry) tarIn.getNextEntry()) != null) {\n",
    "            /** If the entry is a directory, create the directory. **/\n",
    "            if (entry.isDirectory()) {\n",
    "                File f = new File(FilenameUtils.concat(destDir.getPath(),entry.getName()));\n",
    "                boolean created = f.mkdir();\n",
    "                if (!created) {\n",
    "                    System.out.printf(\"Unable to create directory '%s', during extraction of archive contents.\\n\",\n",
    "                            f.getAbsolutePath());\n",
    "                }\n",
    "            } else {\n",
    "                int count;\n",
    "                byte data[] = new byte[BUFFER_SIZE];\n",
    "                FileOutputStream fos = new FileOutputStream(FilenameUtils.concat(destDir.getPath(),entry.getName()), false);\n",
    "                try (BufferedOutputStream dest = new BufferedOutputStream(fos, BUFFER_SIZE)) {\n",
    "                    while ((count = tarIn.read(data, 0, BUFFER_SIZE)) != -1) {\n",
    "                        dest.write(data, 0, count);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//fetch_housing_data(HOUSING_URL, new File(HOUSING_PATH));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tech.tablesaw.api.Table;\n",
    "\n",
    "Table load_housing_data(File housingPathCsv){\n",
    " return Try.of(() ->Table.read().csv(housingPathCsv)).get();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var housing = load_housing_data(new File(FilenameUtils.concat(HOUSING_PATH,\"housing.csv\")));\n",
    "housing.first(4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//planning to replicate housing.info()\n",
    "display(housing.structure());\n",
    "display(housing.shape());\n",
    "display(housing.summary());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.xTabCounts(\"ocean_proximity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tech.tablesaw.plotly.components.Figure;\n",
    "import tech.tablesaw.plotly.components.Layout;\n",
    "import tech.tablesaw.plotly.api.Histogram;  \n",
    "import tech.tablesaw.plotly.Plot;\n",
    "import javax.imageio.ImageIO;\n",
    "import java.io.File;\n",
    "import java.io.FileOutputStream;\n",
    "import java.io.IOException;\n",
    "import java.nio.file.Files;\n",
    "import java.nio.file.Path;\n",
    "import java.nio.file.Paths;\n",
    "import java.util.UUID;\n",
    "import tech.tablesaw.plotly.components.Page;\n",
    "\n",
    "void renderPlotly(Figure fig){\n",
    "    Page page = Page.pageBuilder(fig, \"target\").build();\n",
    "    display(page.asJavascript(),\"text/html\");\n",
    "}\n",
    "\n",
    "//renderPlotly(Histogram.create(\"Distribution of total_rooms\", housing, \"total_rooms\"));\n",
    "\n",
    "// housing.numericColumns().forEach(f ->{\n",
    "//          HistogramTrace trace = HistogramTrace.builder(f.asDoubleArray()).build();\n",
    "//          Plot.show(new Figure(Layout.builder(f.name()).build(), trace));\n",
    "        \n",
    "// });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for stratified sampling\n",
    "*I have skipped random sampling in the book*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.function.ToDoubleFunction;\n",
    "var incomeCat = housing.doubleColumn(\"median_income\").map((ToDoubleFunction<Double>) f -> Math.ceil(f/1.5)).map((ToDoubleFunction<Double>)cat -> cat > 5 ? 5: cat );\n",
    "housing.addColumns(incomeCat.setName(\"income_cat\"));\n",
    "housing.first(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tech.tablesaw.api.CategoricalColumn;\n",
    "import tech.tablesaw.columns.Column;\n",
    "import static tech.tablesaw.aggregate.AggregateFunctions.*;\n",
    "Table[] stratifiedSampleSplit(Table table, String column, double table1Proportion){\n",
    "    final Table first = table.emptyCopy();\n",
    "    final Table second = table.emptyCopy();\n",
    "    String categoricalColumn = column;\n",
    "    Column<?> col = table.column(column);\n",
    "    if(!CategoricalColumn.class.isInstance(col)){\n",
    "        categoricalColumn += \"_stringified\";\n",
    "        table.addColumns(col.asStringColumn().setName(categoricalColumn));\n",
    "    }\n",
    "    table.splitOn(categoricalColumn).asTableList().forEach(tab-> {\n",
    "       Table[] splits = tab.sampleSplit(table1Proportion); \n",
    "        first.append(splits[0]);\n",
    "        second.append(splits[1]);\n",
    "    });\n",
    "    if(!categoricalColumn.equals(column)){\n",
    "        table.removeColumns(table.column(categoricalColumn));\n",
    "    }\n",
    "    return new Table[]{first, second};\n",
    "}\n",
    "\n",
    "var strats = stratifiedSampleSplit(housing,\"income_cat\", 0.2);\n",
    "strats[1].removeColumns(strats[1].column(\"income_cat\"));\n",
    "strats[0].removeColumns(strats[0].column(\"income_cat\"));\n",
    "display(strats[1].shape());\n",
    "display(strats[0].shape());\n",
    "display(strats[0].summarize(\"longitude\",\"median_income\", mean, count).apply());\n",
    "strats[1].summarize(\"longitude\",\"median_income\", mean, count).apply();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and visualize the data to gain insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**skipped for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strats[1].copy();\n",
    "housing.shape();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tablesaw  doesn handle missing values very well so we will set missing values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.missingValueCounts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var tBRoom = housing.intColumn(\"total_bedrooms\");\n",
    "housing.replaceColumn(\"total_bedrooms\",tBRoom.set(tBRoom.isMissing(),0));\n",
    "var summarizer = housing.summarize(\"total_bedrooms\", mean, sum, count).apply();\n",
    "summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.missingValueCounts();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lets save the mean because we will need it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var totalBedroomsMean = summarizer.column(0).get(0);\n",
    "totalBedroomsMean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.stream.*;\n",
    "import org.apache.commons.math3.stat.correlation.PearsonsCorrelation;\n",
    "import io.vavr.Tuple;  \n",
    "\n",
    "var medianVector  = housing.intColumn(\"median_house_value\").asDoubleColumn();\n",
    "\n",
    "var corr = new PearsonsCorrelation();\n",
    "housing.numericColumns().stream()\n",
    "    .map(i -> Tuple.of(i.name(),corr.correlation( i.asDoubleArray(), medianVector.asDoubleArray() )))\n",
    "    .sorted((a, b) -> {\n",
    "        int c = 0;\n",
    "        if( a._2 == Double.NaN  && b._2 == Double.NaN ){\n",
    "            c = 0;\n",
    "        }\n",
    "        else if(b._2 == Double.NaN || a._2 > b._2){\n",
    "            c = 1;\n",
    "        }\n",
    "        else if(a._2 == Double.NaN ||a._2 < b._2){\n",
    "            c = -1;\n",
    "        }\n",
    "        \n",
    "        return c;\n",
    "    })\n",
    "    .collect(Collectors.toList());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Pandas correlation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.addColumns( \n",
    "    housing.nCol(\"total_rooms\").divide(housing.nCol(\"households\")).setName(\"rooms_per_household\"),\n",
    "    housing.nCol(\"total_bedrooms\").divide(housing.nCol(\"total_rooms\")).setName(\"bedrooms_per_room\"),\n",
    "    housing.nCol(\"total_bedrooms\").divide(housing.nCol(\"households\")).setName(\"population_per_household\")\n",
    ");\n",
    "housing.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var medianVector  = housing.intColumn(\"median_house_value\").asDoubleColumn();\n",
    "\n",
    "var corr = new PearsonsCorrelation();\n",
    "housing.numericColumns().stream()\n",
    "    .map(i -> Tuple.of(i.name(),corr.correlation( i.asDoubleArray(), medianVector.asDoubleArray() )))    \n",
    "    .sorted((a, b) -> {\n",
    "        int c = 0;\n",
    "        if( a._2 == Double.NaN  && b._2 == Double.NaN ){\n",
    "            c = 0;\n",
    "        }\n",
    "        else if(b._2 == Double.NaN || a._2 > b._2){\n",
    "            c = 1;\n",
    "        }\n",
    "        else if(a._2 == Double.NaN ||a._2 < b._2){\n",
    "            c = -1;\n",
    "        }\n",
    "        \n",
    "        return c;\n",
    "    })\n",
    "    .collect(Collectors.toList());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.missingValueCounts();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I am going with option 1(Get rid of the corresponding districts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strats[1].copy();\n",
    "housing.addColumns( \n",
    "    housing.nCol(\"total_rooms\").divide(housing.nCol(\"households\")).setName(\"rooms_per_household\"),\n",
    "    housing.nCol(\"total_bedrooms\").divide(housing.nCol(\"total_rooms\")).setName(\"bedrooms_per_room\"),\n",
    "    housing.nCol(\"total_bedrooms\").divide(housing.nCol(\"households\")).setName(\"population_per_household\")\n",
    ");\n",
    "//housing =housing.dropRowsWithMissingValues();\n",
    "housing.missingValueCounts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "import java.util.stream.Collectors;\n",
    "import java.util.stream.IntStream;\n",
    "\n",
    "import weka.core.Attribute;\n",
    "import tech.tablesaw.api.ColumnType;\n",
    "import tech.tablesaw.api.NumericColumn;\n",
    "import tech.tablesaw.api.StringColumn;\n",
    "import tech.tablesaw.columns.Column;\n",
    "import tech.tablesaw.table.Relation;\n",
    "import weka.core.DenseInstance;\n",
    "import weka.core.Instance;\n",
    "import weka.core.Instances;\n",
    "import weka.core.Utils;\n",
    "\n",
    "/**\n",
    " *\n",
    " * @author James Akinniranye\n",
    " */\n",
    "public class WekaConverter {\n",
    "\n",
    "    private Relation table;\n",
    "    private Instances structure;\n",
    "\n",
    "    public WekaConverter() {\n",
    "        \n",
    "    }\n",
    "    public WekaConverter(Relation table) {\n",
    "        this.table = table;\n",
    "    }\n",
    "    \n",
    "    public WekaConverter setRelation(Relation table) {\n",
    "        this.table = table;\n",
    "        return this;\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Returns a dataset where the response column is numeric. E.g. to be used\n",
    "     * for a regression\n",
    "     */\n",
    "    public Instances numericDataset(String classColName) {\n",
    "        return dataset(\n",
    "                table.numberColumn(classColName),\n",
    "                AttributeType.NUMERIC,\n",
    "                table.numericColumns().stream().filter(c -> !c.name().equals(classColName)).collect(Collectors.toList()));\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Returns a dataset where the response column is numeric. E.g. to be used\n",
    "     * for a regression\n",
    "     */\n",
    "    public Instances numericDataset(int classColIndex, int... variablesColIndices) {\n",
    "        return dataset(table.numberColumn(classColIndex), AttributeType.NUMERIC, table.columns(variablesColIndices));\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Returns a dataset where the response column is numeric. E.g. to be used\n",
    "     * for a regression\n",
    "     */\n",
    "    public Instances numericDataset(String classColName, String... variablesColNames) {\n",
    "        return dataset(table.numberColumn(classColName), AttributeType.NUMERIC, table.columns(variablesColNames));\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Returns a dataset where the response column is nominal. E.g. to be used\n",
    "     * for a classification\n",
    "     */\n",
    "    public Instances nominalDataset(String classColName) {\n",
    "        return dataset(\n",
    "                table.numberColumn(classColName),\n",
    "                AttributeType.NOMINAL,\n",
    "                table.numericColumns().stream().filter(c -> !c.name().equals(classColName)).collect(Collectors.toList()));\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Returns a dataset where the response column is nominal. E.g. to be used\n",
    "     * for a classification\n",
    "     */\n",
    "    public Instances nominalDataset(int classColIndex, int... variablesColIndices) {\n",
    "        return dataset(table.numberColumn(classColIndex), AttributeType.NOMINAL, table.columns(variablesColIndices));\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * Returns a dataset where the response column is nominal. E.g. to be used\n",
    "     * for a classification\n",
    "     */\n",
    "    public Instances nominalDataset(String classColName, String... variablesColNames) {\n",
    "        return dataset(table.numberColumn(classColName), AttributeType.NOMINAL, table.columns(variablesColNames));\n",
    "    }\n",
    "\n",
    "    private Instances dataset(NumericColumn<?> classCol, AttributeType type, List<Column<?>> variableCols) {\n",
    "        List<Column<?>> convertedVariableCols = variableCols.stream()\n",
    "                .map(col -> col.type() == ColumnType.STRING ? col : table.nCol(col.name()))\n",
    "                .collect(Collectors.toList());\n",
    "       \n",
    "\n",
    "       \n",
    "        Instances dataset;\n",
    "        if(structure == null){\n",
    "             Attribute classAttribute = type == AttributeType.NOMINAL\n",
    "                ? colAsNominalAttribute(classCol) : new Attribute(classCol.name());\n",
    "            ArrayList<Attribute> attributes = new ArrayList<>(convertedVariableCols.stream().map(col -> colAsAttribute(col)).collect(Collectors.toList()));\n",
    "            attributes.add(classAttribute);\n",
    "            dataset = new Instances(table.name(), attributes,classCol.size());\n",
    "            dataset.setClass(classAttribute);\n",
    "        }\n",
    "        else{\n",
    "            dataset = new Instances(structure,classCol.size());\n",
    "        }\n",
    "        \n",
    "        for (int i = 0; i < classCol.size(); i++) {\n",
    "            Instance inst = new DenseInstance(dataset.numAttributes());\n",
    "            inst.setDataset(dataset);\n",
    "            final int r = i;\n",
    "            IntStream.range(0, dataset.numAttributes()-1)\n",
    "                    .forEach(c -> inst.setValue(c, getDouble(convertedVariableCols.get(c), dataset.attribute(c), r)));\n",
    "            inst.setValue(dataset.numAttributes()-1, getDouble(classCol, dataset.classAttribute(), r));\n",
    "            dataset.add(inst);\n",
    "        }\n",
    "        if(structure == null){\n",
    "            structure  = dataset.stringFreeStructure();\n",
    "        }\n",
    "        dataset.compactify();\n",
    "        return dataset;\n",
    "    }\n",
    "\n",
    "    private double getDouble(Column<?> col, Attribute attr, int r) {\n",
    "        if (col.type() == ColumnType.STRING) {\n",
    "            return attr.indexOfValue(Utils.unquote(((StringColumn) col).get(r)));\n",
    "        }\n",
    "        if (col instanceof NumericColumn) {\n",
    "            return ((NumericColumn<?>) col).getDouble(r);\n",
    "        }\n",
    "        throw new IllegalStateException(\"Error converting \" + col.type() + \" column \" + col.name() + \" to Smile\");\n",
    "    }\n",
    "\n",
    "    private Attribute colAsAttribute(Column<?> col) {\n",
    "        return col.type() == ColumnType.STRING ? colAsNominalAttribute(col) : new Attribute(col.name());\n",
    "    }\n",
    "\n",
    "    private Attribute colAsNominalAttribute(Column<?> col) {\n",
    "        Column<?> unique = col.unique().removeMissing();\n",
    "        Attribute att = new Attribute(col.name(),\n",
    "                unique.mapInto(o -> Utils.unquote(o.toString()), StringColumn.create(col.name(), unique.size())).asList());\n",
    "        //att.setWeight(1.0);\n",
    "        return att;\n",
    "    }\n",
    "\n",
    "    private static enum AttributeType {\n",
    "        NUMERIC,\n",
    "        NOMINAL\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var cols= housing.columnNames().stream().filter(c -> !c.equals(\"median_house_value\")).toArray(String[]::new);\n",
    "var wekaConverter = new WekaConverter(housing);\n",
    "var housingMl = wekaConverter.numericDataset(\"median_house_value\",cols);\n",
    "housingMl.toSummaryString();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.filters.supervised.attribute.NominalToBinary;\n",
    "import weka.filters.unsupervised.attribute.Remove;\n",
    "import weka.filters.Filter;\n",
    "\n",
    "\n",
    "NominalToBinary nom = new NominalToBinary();\n",
    "\n",
    "nom.setInputFormat(housingMl);\n",
    "var h2 = Filter.useFilter(housingMl, nom);\n",
    "\n",
    "h2.toSummaryString();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2.firstInstance();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.filters.unsupervised.attribute.ReplaceMissingValues;\n",
    "var rpl = new ReplaceMissingValues();\n",
    "rpl.setInputFormat(h2);\n",
    "\n",
    "h2 = Filter.useFilter(h2, rpl);\n",
    "\n",
    "h2.toSummaryString();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import weka.classifiers.functions.SimpleLinearRegression;\n",
    "import weka.filters.unsupervised.instance.Resample;\n",
    "import weka.classifiers.evaluation.EvaluationUtils;\n",
    "import weka.filters.Filter;\n",
    "\n",
    "var linerReg = new SimpleLinearRegression();\n",
    "\n",
    "Resample resample = new Resample();\n",
    "resample.setInputFormat(h2);\n",
    "resample.setSampleSizePercent((double)5*100/h2.size());\n",
    "var evalUtil = new EvaluationUtils();\n",
    "var testH2 = Filter.useFilter(h2, resample);\n",
    "evalUtil.getTrainTestPredictions(linerReg, h2, testH2 )\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.classifiers.functions.LinearRegression;\n",
    "\n",
    "var linerReg = new LinearRegression();\n",
    "evalUtil.getTrainTestPredictions(linerReg, h2, testH2)\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.filters.Filter;\n",
    "import java.util.function.Function;\n",
    "import java.util.HashMap;\n",
    "class Pipeline{\n",
    "    \n",
    "    private final Filter[] filters;\n",
    "    private final String[] attributeCols;\n",
    "    private final String classAttribute;\n",
    "    private WekaConverter converter;\n",
    "    private Function<Relation, Relation> preProcessors;\n",
    "    private final HashMap<Integer,Boolean> checks = new HashMap<>();\n",
    "    public Pipeline( String[] attributeCols, String classAttribute, Filter... filters ){\n",
    "        this.attributeCols = attributeCols;\n",
    "        this.classAttribute = classAttribute;\n",
    "        this.filters = filters;\n",
    "    }\n",
    "    \n",
    "    public void setPreProcessing(Function<Relation, Relation> preProcessors){\n",
    "        this.preProcessors = preProcessors;\n",
    "    }\n",
    "    \n",
    "    public Instances fitTransom(Relation data){\n",
    "        if(converter == null){\n",
    "            converter = new WekaConverter();\n",
    "        }\n",
    "        if(preProcessors != null){\n",
    "                data = preProcessors.apply(data);\n",
    "        }\n",
    "        Instances inst = converter.setRelation(data).numericDataset(classAttribute,attributeCols);\n",
    "        Instances result = inst;\n",
    "        for(Filter filter : filters){\n",
    "            if(!checks.containsKey(filter.hashCode()) ){\n",
    "               Try.run(() ->  filter.setInputFormat(inst));\n",
    "               checks.put(filter.hashCode(), true);\n",
    "            }\n",
    "            Instances resultTemp = result;\n",
    "            result = Try.of(() -> Filter.useFilter(resultTemp, filter)).get();\n",
    "        }\n",
    "        return result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.filters.unsupervised.attribute.Standardize;\n",
    "\n",
    "var cols= housing.columnNames().stream().filter(c -> !c.equals(\"median_house_value\")).toArray(String[]::new);\n",
    "var pipe = new Pipeline(cols, \"median_house_value\", \n",
    "    new ReplaceMissingValues(), new Standardize(), new NominalToBinary() );\n",
    "Function<Relation,Relation> func = (hous) -> hous.addColumns( \n",
    "    hous.nCol(\"total_rooms\").divide(hous.nCol(\"households\")).setName(\"rooms_per_household\"),\n",
    "    hous.nCol(\"total_bedrooms\").divide(hous.nCol(\"total_rooms\")).setName(\"bedrooms_per_room\"),\n",
    "    hous.nCol(\"total_bedrooms\").divide(hous.nCol(\"households\")).setName(\"population_per_household\")\n",
    ");\n",
    "pipe.setPreProcessing(func);\n",
    "var d = pipe.fitTransom(strats[1].copy());\n",
    "Resample resample = new Resample();\n",
    "resample.setInputFormat(d);\n",
    "resample.setSampleSizePercent((double)5*100/d.size());\n",
    "\n",
    "var dtest = Filter.useFilter(d, resample);\n",
    "dtest;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var linerReg = new LinearRegression();\n",
    "linerReg.buildClassifier(d);\n",
    "evalUtil.getTestPredictions(linerReg, dtest)\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import weka.classifiers.Evaluation;\n",
    " import java.util.Random;\n",
    "\n",
    "var linerReg = new LinearRegression();\n",
    "Evaluation eval = new Evaluation(d);\n",
    "eval.crossValidateModel(linerReg, d, 10, new Random(1));\n",
    "display(\"** Linear Regression Evaluation with Datasets **\");\n",
    "display(eval.toSummaryString(false));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.classifiers.rules.DecisionTable;\n",
    "\n",
    "var desc = new DecisionTable();\n",
    "Evaluation eval = new Evaluation(d);\n",
    "eval.crossValidateModel(desc, d, 10, new Random(1));\n",
    "display(\"** DecisionTable Evaluation with Datasets **\");\n",
    "display(eval.toSummaryString(false));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc.buildClassifier(d);\n",
    "evalUtil.getTestPredictions(desc,  dtest)\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.classifiers.trees.RandomForest;\n",
    "\n",
    "RandomForest forest=new RandomForest();\n",
    "//increasing i to 100 makes the model better\n",
    "forest.setOptions(new String[]{\"-I\", \"10\"});\n",
    "Evaluation eval = new Evaluation(d);\n",
    "eval.crossValidateModel(forest, d, 10, new Random(1));\n",
    "display(\"** RandomForest Regression Evaluation with Datasets **\");\n",
    "display(eval.toSummaryString(false));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "//RandomForest forest=new RandomForest();\n",
    "forest.buildClassifier(d);\n",
    "forest.setOptions(new String[]{\"-I\", \"20\"});\n",
    "evalUtil.getTestPredictions(forest,  dtest)\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.classifiers.functions.SMOreg;\n",
    "\n",
    "var svm = new SMOreg();\n",
    "svm.setOptions(new String[]{\"-N\",\"0\"});\n",
    "Evaluation eval = new Evaluation(d);\n",
    "eval.crossValidateModel(desc, d, 10, new Random(1));\n",
    "display(\"** SMO SVM Evaluation with Datasets **\");\n",
    "display(eval.toSummaryString(false));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.buildClassifier(d);\n",
    "evalUtil.getTestPredictions(svm,  dtest)\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.classifiers.meta.GridSearch;\n",
    "var grid = new GridSearch();\n",
    "grid.setOptions(new String[]{\"-E\",\"RMSE\",\"-D\"});\n",
    "grid.buildClassifier(d);\n",
    "grid.enumerateMeasures();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.getBestClassifier();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.getBestFilter();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.getEvaluation();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalUtil.getTestPredictions(grid.getBestClassifier(),  dtest)\n",
    "    .forEach(c -> display(\"test \"+ c.actual() + \" predicted = \"+ c.predicted() ));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "12.0.1+12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
